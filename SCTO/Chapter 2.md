![](https://qph.cf2.quoracdn.net/main-qimg-a68fc28294a8963b59bd21ec31a0277a)

# Chapter 2: Literature Review 

## Introduction

[Privacy-Preserving Data Mining (PPDM) has emerged as an absolute prerequisite for exchanging confidential information in terms of data analysis, validation, and publishing](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x)[1](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x). [The dramatic increase of storing customers’ personal data led to an enhanced complexity of data mining algorithm with significant impact on the information sharing](https://link.springer.com/article/10.1007/s10462-023-10425-3)[2](https://link.springer.com/article/10.1007/s10462-023-10425-3).

## Classification of PPDM Techniques

[The current privacy preserving data mining techniques are classified based on distortion, association rule, hide association rule, taxonomy, clustering, associative classification, outsourced data mining, distributed, and k-anonymity](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x)[1](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x). [These methods have different strengths and weaknesses concerning the accuracy, privacy, time consumption, and more](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x)[2](https://link.springer.com/article/10.1007/s10462-023-10425-3).

### Perturbation

Perturbation is a technique that involves adding noise to the data to preserve privacy. [However, it must be carefully managed to ensure that the utility of the data is not significantly compromised](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x)[2](https://link.springer.com/article/10.1007/s10462-023-10425-3).

### Secure Multi-party Computation

[Secure Multi-party Computation is a subfield of cryptography that enables multiple parties to compute a function over their inputs while keeping those inputs private](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x)[1](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x).

### Differential Privacy

[Differential Privacy is a system for publicly sharing information about a dataset by describing the patterns of groups within the dataset while withholding information about individuals in the dataset](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x)[1](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x).

### Federated Learning

[Federated Learning is a machine learning approach where a model is trained across multiple decentralized devices or servers holding local data samples, without exchanging them](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x)[1](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x).

## Challenges and Future Trends

[The trade-off between data mining accuracy and data privacy is a significant concern in the area](https://link.springer.com/article/10.1007/s10462-023-10425-3)[2](https://link.springer.com/article/10.1007/s10462-023-10425-3). [There is a lack of studies providing solutions to the issue, especially in Privacy-Preserving Data Stream Mining (PPDSM)](https://link.springer.com/article/10.1007/s10462-023-10425-3)[2](https://link.springer.com/article/10.1007/s10462-023-10425-3). [Further significant enhancements for more robust privacy protection and preservation are affirmed to be mandatory](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x)[1](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x).


---

# Comparison of Privacy-Preserving Data Mining Techniques

|Technique|Description|Advantages|Disadvantages|
|---|---|---|---|
|**Data Anonymization**|[Modifies the data in such a way that individual records cannot be traced back](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[1](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[2](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x).|[Protects individual identities](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[1](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[2](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x).|[May reduce data utility](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[1](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[2](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x).|
|**Secure Multi-party Computation**|[Enables multiple parties to compute a function over their inputs while keeping those inputs private](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[1](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[2](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x).|[Ensures data privacy during computation](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[1](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[2](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x).|[Computationally expensive](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[1](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[2](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x).|
|**Differential Privacy**|[Publicly shares information about a dataset by describing the patterns of groups within the dataset while withholding information about individuals](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[1](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[2](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x).|[Provides strong privacy guarantees](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[1](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[2](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x).|[May introduce noise into the data](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[1](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[2](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x).|
|**Federated Learning**|[Trains a model across multiple decentralized devices or servers holding local data samples, without exchanging them](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[1](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[2](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x).|[Preserves data privacy and reduces data movement](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[1](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[2](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x).|[Requires careful coordination and can be slower than centralized learning](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[1](https://link.springer.com/chapter/10.1007/978-981-13-2354-6_54)[2](https://springerplus.springeropen.com/articles/10.1186/s40064-015-1481-x).|

---

I hope this helps! If you have any more questions or need further clarification, feel free to ask.

## Reference 

<iframe width="560" height="315" src="https://www.youtube.com/embed/ZsjUIXu5hbU?si=tJ4evuPD_KzjUHTz" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
